{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch是什么?\n",
    "================\n",
    "\n",
    "基于Python的科学计算包，服务于以下两种场景:\n",
    "\n",
    "-  作为NumPy的替代品，可以使用GPU的强大计算能力\n",
    "-  提供最大的灵活性和高速的深度学习研究平台\n",
    "    \n",
    "\n",
    "开始\n",
    "---------------\n",
    "\n",
    "Tensors（张量）\n",
    "\n",
    "^^^^^^^\n",
    "\n",
    "Tensors与Numpy中的 ndarrays类似，但是在PyTorch中\n",
    "Tensors 可以使用GPU进行计算.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个 5x3 矩阵, 但是未初始化:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[9.2755e-39, 8.9082e-39, 9.9184e-39],\n        [8.4490e-39, 9.6429e-39, 1.0653e-38],\n        [1.0469e-38, 4.2246e-39, 1.0378e-38],\n        [9.6429e-39, 9.2755e-39, 9.7346e-39],\n        [1.0745e-38, 1.0102e-38, 9.9184e-39]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个随机初始化的矩阵:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[2.7680e-01, 1.1993e-01, 2.8558e-01],\n        [4.7255e-01, 1.8043e-01, 3.5800e-01],\n        [4.9951e-02, 3.4413e-01, 7.8774e-01],\n        [7.6343e-01, 7.6234e-05, 2.9646e-01],\n        [4.8603e-01, 8.1187e-02, 5.2668e-01]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "numpy.random.randn(d0, d1, …, dn)是从标准正态分布中返回一个或多个样本值。\n",
    "\n",
    "numpy.random.rand(d0, d1, …, dn)的随机样本位于[0, 1)中。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[-0.0236,  0.3383, -1.2763],\n        [ 0.7706, -0.3890,  1.2108],\n        [ 1.1161, -0.4402,  0.5478],\n        [ 0.4175,  0.7319, -0.2931],\n        [-2.2566,  0.8338, -0.0759]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x1 = torch.randn(5,3)\n",
    "print(x1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个0填充的矩阵，数据类型为long:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建tensor并使用现有数据初始化:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([5.5000, 3.0000])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)",
      "\n",
      "tensor([[ 0.1091,  0.3419, -0.7229],\n        [-1.8782,  0.3555,  0.1134],\n        [-0.3559,  0.7840, -0.7830],\n        [ 0.6164, -0.2179, -1.7190],\n        [-0.2747, -1.5039, -1.8032]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* 方法来创建对象\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # 覆盖 dtype!\n",
    "print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取 size\n",
    "\n",
    "***译者注：使用size方法与Numpy的shape属性返回的相同，张量也支持shape属性，后面会详细介绍***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([5, 3])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` 返回值是 tuple类型, 所以它支持tuple类型的所有操作.</p></div>\n",
    "\n",
    "操作\n",
    "\n",
    "^^^^^^^^^^\n",
    "\n",
    "操作有多种语法。 \n",
    "\n",
    "我们将看一下加法运算。\n",
    "\n",
    "加法1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1.5770, 1.3970, 1.3461],\n        [1.2015, 1.7312, 1.6921],\n        [1.2430, 1.0794, 1.2750],\n        [0.9743, 1.5710, 1.2747],\n        [1.8895, 1.6093, 1.4023]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.6669,  1.0498, -0.1834],\n        [-1.4226,  0.9581,  0.1555],\n        [ 0.0267,  1.1949, -0.0957],\n        [ 0.7452,  0.3283, -1.0477],\n        [ 0.3409, -1.2963, -0.8829]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提供输出tensor作为参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.6669,  1.0498, -0.1834],\n        [-1.4226,  0.9581,  0.1555],\n        [ 0.0267,  1.1949, -0.0957],\n        [ 0.7452,  0.3283, -1.0477],\n        [ 0.3409, -1.2963, -0.8829]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.6669,  1.0498, -0.1834],\n        [-1.4226,  0.9581,  0.1555],\n        [ 0.0267,  1.1949, -0.0957],\n        [ 0.7452,  0.3283, -1.0477],\n        [ 0.3409, -1.2963, -0.8829]])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>任何 以``_`` 结尾的操作都会用结果替换原变量.\n",
    "    例如: ``x.copy_(y)``, ``x.t_()``, 都会改变 ``x``.</p></div>\n",
    "\n",
    "你可以使用与NumPy索引方式相同的操作来进行对张量的操作\n",
    "\n",
    "使用x[:,n]提取第n-1列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([ 0.3419,  0.3555,  0.7840, -0.2179, -1.5039])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(x[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用x[n,:]提取第n-1行\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-0bfac437a5a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ],
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error"
    }
   ],
   "source": [
    "print(x[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``torch.view``: 可以改变张量的维度和大小\n",
    "\n",
    "***译者注：torch.view 与Numpy的reshape类似***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([4, 4])",
      " ",
      "torch.Size([16])",
      " ",
      "torch.Size([2, 8])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  #  size -1 从其他维度推断\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有只有一个元素的张量，使用``.item()``来得到Python数据类型的数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([0.9288])",
      "\n",
      "0.928820788860321",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described\n",
    "  `here <https://pytorch.org/docs/torch>`_.\n",
    "\n",
    "NumPy 转换\n",
    "------------\n",
    "\n",
    "将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。\n",
    "\n",
    "Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。\n",
    "\n",
    "将一个Torch Tensor转换为NumPy数组\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1.])",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1. 1. 1. 1. 1.]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察numpy数组的值是如何改变的。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([2., 2., 2., 2., 2.])",
      "\n",
      "[2. 2. 2. 2. 2.]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NumPy Array 转化成 Torch Tensor\n",
    "\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "使用from_numpy自动转化\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[2. 2. 2. 2. 2.]",
      "\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到\n",
    "NumPy 的转换.\n",
    "CUDA 张量\n",
    "------------\n",
    "\n",
    "使用``.to`` 方法 可以将Tensor移动到任何设备中\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# is_available 函数判断是否有cuda可以使用\n",
    "# ``torch.device``将张量移动到指定的设备中\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA 设备对象\n",
    "    y = torch.ones_like(x, device=device)  # 直接从GPU创建张量\n",
    "    x = x.to(device)                       # 或者直接使用``.to(\"cuda\")``将张量移动到cuda中\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 也会对变量的类型做更改\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}